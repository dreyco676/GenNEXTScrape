from selenium import webdriver
from bs4 import BeautifulSoup
import time
import json
import csv
import os
import urllib

BASE_URL = 'http://w20.education.state.mn.us'
DATA_PATH = 'downloads/'

def get_main_menu():
    """Retrieve a menu of report categories from the MN Dept of Education
    and save to a CSV file"""
    data = []
    url = BASE_URL +  '/MDEAnalytics/Data.jsp'
    driver = webdriver.Chrome()
    driver.get(url)
    time.sleep(1)
    driver.switch_to_frame(driver.find_element_by_id('floatframe'))
    html = driver.page_source
    driver.close()
    soup = BeautifulSoup(html)
    soup = BeautifulSoup(html)
    table = soup.select('table')[0]
    rowno = 0
    for tr in table.select('tr'):
        td = tr.select('td')
        if len(td) == 2:
            for a in td[1]('a'):
                rowno += 1
                data.append([rowno, a.text.strip(), a['href']])
                break
    with open('../report_list.csv', 'wb') as outfile:
        writer = csv.writer(outfile)
        writer.writerow(('id', 'reportType', 'url'))
        writer.writerows(data)
        

def get_report_url(search_text):
    """Retrieve a list of reports by id number, as listed in the
    CSV file generated by get_main_menu()"""
    with open('../report_list.csv', 'r') as infile:
        reader = csv.reader(infile)
        if isinstance(search_text, int):
            return list(reader)[search_text][2]
        search_text = search_text.lower().strip()
        next(reader)
        for rowno, title, url in reader:
            if search_text == title.lower.strip():
                return url


def download_reports(url):
    """Download all available reports by url. Use the get_report_url()
    function to lookup the url."""
    url = BASE_URL + url
    driver = webdriver.Chrome()
    driver.get(url)
    button1 = driver.find_element_by_css_selector('#button1')
    button1.click()
    time.sleep(3)
    driver.switch_to_frame(driver.find_element_by_id('ifReport'))
    html = driver.page_source
    driver.close()
    soup = BeautifulSoup(html)
    div = soup.select('div.scrollDiv')[0]
    rows = div('tr')
    colnames = [th.text.strip() for th in rows[1]('th')]
    document_index = colnames.index('Document')
    data_index = colnames.index('Data Files')
    for tr in rows[2:]:
        row = tr('td')
        filename = row[document_index].text.strip().replace(' ', '_')
        for a in row[data_index]('a'):
            full_filename = DATA_PATH + filename + '.' + a.text.strip()
            url = a['href'].strip()
            print 'Downloading %s' % full_filename
            urllib.urlretrieve(url, full_filename)
        

    
if __name__ == '__main__':
    get_main_menu()
    url = get_report_url(44)  # Download staff data
    download_reports(url)
